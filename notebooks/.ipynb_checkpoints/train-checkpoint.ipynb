{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "ss = nltk.corpus.brown.tagged_sents(tagset='universal')\n",
    "ww = nltk.corpus.brown.tagged_words(tagset='universal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /Users/tianhaolu/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_count = 0\n",
    "wd_idx = {}\n",
    "tag_count = 0\n",
    "tag_idx = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in ww:\n",
    "    wd, tag = pair[0], pair[1]\n",
    "    if wd not in wd_idx:\n",
    "        wd_idx[wd] = wd_count\n",
    "        wd_count += 1\n",
    "    if tag not in tag_idx:\n",
    "        tag_idx[tag] = tag_count\n",
    "        tag_count += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 5,\n",
       " 'ADJ': 2,\n",
       " 'ADP': 4,\n",
       " 'ADV': 6,\n",
       " 'CONJ': 7,\n",
       " 'DET': 0,\n",
       " 'NOUN': 1,\n",
       " 'NUM': 10,\n",
       " 'PRON': 9,\n",
       " 'PRT': 8,\n",
       " 'VERB': 3,\n",
       " 'X': 11}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "goal is to maximize <br>\n",
    "$l(\\theta) = \\Sigma_{i}^{N}logp(y^i|x^i)$\n",
    "<br>\n",
    "\n",
    "$ = \\Sigma_{i}^{N}\\Sigma_{t}^{T}\\Sigma_{k}^{K}\\lambda_k f_k(y_t^i,y_{t-1}^i, x_t^i) - \\Sigma_{i}^{N}logZ(x^i)$\n",
    "<br>\n",
    "With Gradient Ascent, we need to compute\n",
    "<br>\n",
    "<br>\n",
    "$\\frac{\\partial l}{\\partial \\lambda_k} = \\Sigma_{i}^{N}\\Sigma_{t}^{T}f_k(y_t^i,y_{t-1}^i, x_t^i) - \\Sigma_{i}^{N}\\Sigma_{t}^{T}\\Sigma_{y, y'}f_k(y,y',x_t^i)p(y,y'|x^i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume M tag states and V vocabs, we need M*M+M*V feature fns;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first term $\\Sigma_{i}^{N}\\Sigma_{t}^{T}f_k(y_t^i,y_{t-1}^i, x_t^i)$ can be cached as it remains the same w.r.t. empirical (training) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_sum_yy = np.zeros((tag_count, tag_count))\n",
    "emp_sum_yx = np.zeros((tag_count, wd_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sent in enumerate(ss):\n",
    "    for t, pair in enumerate(sent):\n",
    "        wd, tag = sent[t][0],sent[t][1] \n",
    "#         print (wd, tag)\n",
    "        emp_sum_yx[tag_idx[tag],wd_idx[wd]] += 1\n",
    "        if t < len(sent)-1:\n",
    "            tag_next = sent[t+1][1]\n",
    "            emp_sum_yy[tag_idx[tag_next],tag_idx[tag]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.0900e+02, 4.2700e+03, 4.8900e+02, 2.9784e+04, 6.5960e+04,\n",
       "        1.0003e+04, 4.1360e+03, 5.7720e+03, 2.4920e+03, 8.6400e+02,\n",
       "        1.9500e+02, 7.0000e+00],\n",
       "       [8.5838e+04, 4.1144e+04, 5.4645e+04, 1.7819e+04, 3.7415e+04,\n",
       "        1.2226e+04, 1.8460e+03, 9.2940e+03, 1.0660e+03, 4.3700e+02,\n",
       "        5.6590e+03, 7.6000e+01],\n",
       "       [3.2846e+04, 3.5530e+03, 4.7650e+03, 1.0510e+04, 1.1961e+04,\n",
       "        4.2610e+03, 7.6660e+03, 4.2720e+03, 5.6400e+02, 4.6800e+02,\n",
       "        8.8200e+02, 4.0000e+00],\n",
       "       [8.8610e+03, 4.3763e+04, 1.4630e+03, 3.3667e+04, 5.9670e+03,\n",
       "        1.1313e+04, 1.3518e+04, 7.4550e+03, 1.8568e+04, 3.4838e+04,\n",
       "        6.7700e+02, 7.2000e+01],\n",
       "       [1.2430e+03, 6.7325e+04, 7.4070e+03, 3.0925e+04, 2.9390e+03,\n",
       "        9.6250e+03, 7.9790e+03, 2.7960e+03, 2.7060e+03, 2.7530e+03,\n",
       "        1.9500e+03, 7.4000e+01],\n",
       "       [1.7510e+03, 7.8181e+04, 8.4040e+03, 1.4733e+04, 1.4110e+03,\n",
       "        1.5811e+04, 9.5700e+03, 7.9400e+02, 2.2880e+03, 5.1160e+03,\n",
       "        4.0270e+03, 3.8000e+02],\n",
       "       [2.4000e+03, 7.2720e+03, 8.1000e+02, 1.8859e+04, 2.2440e+03,\n",
       "        6.4290e+03, 5.4460e+03, 3.4840e+03, 1.0790e+03, 2.6650e+03,\n",
       "        3.0300e+02, 1.0000e+01],\n",
       "       [8.8000e+01, 1.6447e+04, 3.1470e+03, 2.6280e+03, 2.7300e+02,\n",
       "        1.0239e+04, 9.7400e+02, 1.0000e+01, 3.6400e+02, 5.6200e+02,\n",
       "        5.7000e+02, 3.2000e+01],\n",
       "       [2.7500e+02, 4.9150e+03, 1.6140e+03, 1.1987e+04, 2.0620e+03,\n",
       "        2.7050e+03, 1.6130e+03, 9.5900e+02, 3.3500e+02, 1.1720e+03,\n",
       "        7.9000e+01, 1.0000e+01],\n",
       "       [1.3580e+03, 5.4600e+03, 3.2000e+02, 1.0058e+04, 1.0102e+04,\n",
       "        6.8380e+03, 2.7190e+03, 2.5790e+03, 2.0400e+02, 4.0400e+02,\n",
       "        1.2600e+02, 9.0000e+00],\n",
       "       [1.3380e+03, 2.2220e+03, 5.8400e+02, 1.6440e+03, 4.3570e+03,\n",
       "        1.7800e+03, 7.4700e+02, 7.1300e+02, 1.5200e+02, 4.9000e+01,\n",
       "        3.2300e+02, 1.0000e+00],\n",
       "       [1.9400e+02, 9.2000e+01, 4.2000e+01, 3.4000e+01, 6.7000e+01,\n",
       "        1.8600e+02, 5.0000e+00, 2.1000e+01, 2.0000e+00, 1.0000e+00,\n",
       "        3.0000e+00, 7.0900e+02]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp_sum_yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
