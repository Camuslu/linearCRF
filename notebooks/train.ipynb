{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "ss = nltk.corpus.brown.tagged_sents(tagset='universal')\n",
    "ww = nltk.corpus.brown.tagged_words(tagset='universal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.corpus.reader.util.ConcatenatedCorpusView"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "sent_len = defaultdict(int)\n",
    "for s in ss:\n",
    "    sent_len[len(s)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /Users/tianhaolu/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_count = 0\n",
    "wd_idx = {}\n",
    "tag_count = 0\n",
    "tag_idx = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in ww:\n",
    "    wd, tag = pair[0], pair[1]\n",
    "    if wd not in wd_idx:\n",
    "        wd_idx[wd] = wd_count\n",
    "        wd_count += 1\n",
    "    if tag not in tag_idx:\n",
    "        tag_idx[tag] = tag_count\n",
    "        tag_count += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 5,\n",
       " 'ADJ': 2,\n",
       " 'ADP': 4,\n",
       " 'ADV': 6,\n",
       " 'CONJ': 7,\n",
       " 'DET': 0,\n",
       " 'NOUN': 1,\n",
       " 'NUM': 10,\n",
       " 'PRON': 9,\n",
       " 'PRT': 8,\n",
       " 'VERB': 3,\n",
       " 'X': 11}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "goal is to maximize <br>\n",
    "$l(\\theta) = \\Sigma_{i}^{N}logp(y^i|x^i)$\n",
    "<br>\n",
    "\n",
    "$ = \\Sigma_{i}^{N}\\Sigma_{t}^{T}\\Sigma_{k}^{K}\\lambda_k f_k(y_t^i,y_{t-1}^i, x_t^i) - \\Sigma_{i}^{N}logZ(x^i)$\n",
    "<br>\n",
    "With Gradient Ascent, we need to compute\n",
    "<br>\n",
    "<br>\n",
    "$\\frac{\\partial l}{\\partial \\lambda_k} = \\Sigma_{i}^{N}\\Sigma_{t}^{T}f_k(y_t^i,y_{t-1}^i, x_t^i) - \\Sigma_{i}^{N}\\Sigma_{t}^{T}\\Sigma_{y, y'}f_k(y,y',x_t^i)p(y,y'|x^i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume M tag states and V vocabs, we need M*M+M*V feature fns;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first term $\\Sigma_{i}^{N}\\Sigma_{t}^{T}f_k(y_t^i,y_{t-1}^i, x_t^i)$ can be cached as it remains the same w.r.t. empirical (training) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_sum_yy = np.zeros((tag_count, tag_count))\n",
    "emp_sum_yx = np.zeros((tag_count, wd_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sent in enumerate(ss):\n",
    "    for t, pair in enumerate(sent):\n",
    "        if len(sent) >= 2:\n",
    "            wd, tag = sent[t][0],sent[t][1] \n",
    "    #         print (wd, tag)\n",
    "            emp_sum_yx[tag_idx[tag],wd_idx[wd]] += 1\n",
    "            if t < len(sent)-1:\n",
    "                tag_next = sent[t+1][1]\n",
    "                emp_sum_yy[tag_idx[tag_next],tag_idx[tag]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.257e+03, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [0.000e+00, 1.700e+01, 8.500e+01, ..., 0.000e+00, 1.000e+00,\n",
       "        0.000e+00],\n",
       "       [0.000e+00, 0.000e+00, 0.000e+00, ..., 1.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       ...,\n",
       "       [0.000e+00, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [0.000e+00, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [0.000e+00, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp_sum_yx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Z(x) = \\Sigma_{y_T...y_1}\\Pi_{t=1}^{T}\\psi_t({y_t,y_{t-1},x_t})$<br>\n",
    "\n",
    "$ = \\Sigma_{y_T}\\Sigma_{y_{T-1}}\\psi_T(y_T,y_{T-1},x_T)\\Sigma_{y_{T-2}}\\psi_{T-1}(y_{T-1},y_{T-2},x_{T-1})...\\Sigma_{y_{1}}\\psi_{2}(y_{2},y_{1},x_{2})\\psi_{1}(y_{1},y_{0},x_{1})$\n",
    "\n",
    "if we compute it from right to left, we can define <br>$\\alpha_t(j) := \\Sigma_{y_{t-1}}\\psi_t(y_t=j,y_{t-1},x_t)...\\Sigma_{y_{1}}\\psi_{2}(y_{2},y_{1},x_{2})\\psi_{1}(y_{1},y_{0},x_{1})$<br>\n",
    "and have recursion <br>$\\alpha_t(j) = \\Sigma_{y_{t-1}=i}\\psi_{t}(y_{t}=j,y_{t-1}=i,x_{t})\\alpha_{t-1}(i)$ <br>\n",
    "\n",
    "Finally,\n",
    "$Z(x) = \\Sigma_{y_T = i}\\alpha_{T}(i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Z(weights, i):\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
